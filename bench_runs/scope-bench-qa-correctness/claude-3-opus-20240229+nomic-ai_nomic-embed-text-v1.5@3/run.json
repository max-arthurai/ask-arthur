{"id": "f5b9a640-a2a9-4eba-b73b-dff1734994c8", "name": "claude-3-opus-20240229+nomic-ai_nomic-embed-text-v1.5@3", "test_suite_id": "5d0d8642-7bbf-4d7d-a744-cfdee7647a3a", "test_cases": [{"id": "9302872f-61dc-4092-add4-0b928fc05679", "output": "Based on the FAQ, the main enrichments available in Arthur are:\n\n1. Anomaly Detection\n2. Bias Mitigation \n3. Explainability\n\nTo enable explainability specifically, you need to provide Arthur access to your model's predict function.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "1a3cfeeb-c6a0-41de-9444-c609ec78bc71", "output": "Based on the given context, there is no information about which specific model types do not allow explainability. The article discusses model schemas in general and provides an example for a tabular classification model, but does not go into details about explainability limitations of different model architectures.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "2b285103-b671-43c0-8485-3253fadcc23e", "output": "Based on the provided context, there is no information about which specific enrichments are available for object detection models in Arthur. The context is a general FAQ about using the Arthur platform, but does not go into details about supported enrichments for particular model types.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "640965fd-e43b-4794-9719-de37084d9221", "output": "Based on the context provided, the following enrichments are available for tabular multiclass classification models in Arthur:\n\n- Anomaly Detection\n- Hot Spots\n- Explainability\n\nThe context does not mention which enrichments are available specifically for tabular binary classification models.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "16e9a74b-faca-45ac-aea5-5fbf28ea0c85", "output": "Based on the provided context, there is no information about the specific alert levels available in Arthur. The FAQ does not cover details about the alerting system or alert levels.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "45550df3-ab06-4bde-b929-4e84c7796b80", "output": "Based on the provided context, there are no specific additional requirements mentioned for on-prem deployment in airgapped mode. The context only states that the Arthur platform can be installed without Internet access, once all the required files are downloaded and available locally.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "c8c0a65e-7374-4abe-9d68-458a7a0d48c0", "output": "To enable explainability for your model in Arthur, you need to provide access to the model's predict function. Arthur generally does not need a copy of your actual model, but it does require access to the predict function in order to generate explanations for the model's predictions.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "15379cb5-bba6-43d1-8b2f-80b2a00d0227", "output": "No, KMS (Key Management Service) is not mentioned as a requirement for Arthur's backup and restore capability based on the provided context. The document outlines the steps to restore various components like RDS Postgres, ClickHouse data, messaging infrastructure, and enrichments, but does not indicate that KMS is needed.", "score": -1.0, "input": null, "reference_output": null, "score_result": {"score": -1.0, "category": {"name": "invalid", "description": "grader returned an invalid response"}}}, {"id": "242d60dd-516d-4724-b515-fc5acd86f83c", "output": "I apologize, but the given context does not contain information about Bench scorers for evaluating LLM summary writing. The context discusses token likelihood for generative text models, but does not mention any specific evaluation metrics or scorers for summaries.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "bde29bd5-7fc5-4b40-811f-f03f6a8eeaca", "output": "Based on the context provided, Arthur Bench will include a scoring workflow for manually evaluating LLM responses to questions. This workflow follows the procedure used in the hallucination experiment described, where LLM responses were categorized as either:\n\n1. Correct answer\n2. Not attempting to answer the question \n3. Containing a hallucination", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "7c3bdff6-414e-49b6-ac52-ad6a7d168f13", "output": "Based on the provided context, there is no information about specific Bench scorers that can be used for evaluating LLMs at coding tasks. The context discusses configuring the exact_match scorer to be case-insensitive, but does not mention any code evaluation scorers.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "8d479d1b-5ed7-4926-8d58-5282a8248eee", "output": "Based on the provided context, there are two ways to view your Bench test results:\n\n1. Local: Set the BENCH_FILE_DIR environment variable to point to the location of your test runs, then run `bench` from the command line to launch the local UI in your browser.\n\n2. SaaS (Coming Soon): Set the ARTHUR_BENCH_AUTOLOG, ARTHUR_API_URL, and ARTHUR_API_KEY environment variables to log results to the Arthur platform.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "a88c1ebb-490c-4669-91c3-ca56bc83861e", "output": "Based on the context provided, the key differences between test suites and test runs in Arthur Bench are:\n\n- A test suite defines the inputs, reference outputs, and scoring method to use for evaluating an AI model\n- A test run executes a test suite, passing in the candidate model outputs to compare against the reference outputs\n\nIn summary, a test suite specifies what to test, while a test run actually performs the testing using the suite's configuration.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}], "updated_at": "2024-03-27T11:34:45.716567", "created_at": "2024-03-27T11:34:45.716567", "page": null, "page_size": null, "total_pages": null, "total_count": null}