{"id": "5d0d8642-7bbf-4d7d-a744-cfdee7647a3a", "name": "scope-bench-qa-correctness", "scoring_method": {"name": "qa_correctness", "type": "built_in", "config": {}, "output_type": "categorical", "categories": [{"name": "incorrect", "description": "model output is incorrect given the context"}, {"name": "correct", "description": "model output is correct given the context"}, {"name": "invalid", "description": "grader returned an invalid response"}]}, "test_cases": [{"id": "9302872f-61dc-4092-add4-0b928fc05679", "input": "What enrichments are available in Arthur?", "reference_output": null}, {"id": "1a3cfeeb-c6a0-41de-9444-c609ec78bc71", "input": "What model types do not allow explainability?", "reference_output": null}, {"id": "2b285103-b671-43c0-8485-3253fadcc23e", "input": "What enrichments are available for object detection models?", "reference_output": null}, {"id": "640965fd-e43b-4794-9719-de37084d9221", "input": "What enrichments are available for tabular binary classification models?", "reference_output": null}, {"id": "16e9a74b-faca-45ac-aea5-5fbf28ea0c85", "input": "What are the two alert levels available in Arthur? ", "reference_output": null}, {"id": "45550df3-ab06-4bde-b929-4e84c7796b80", "input": "What are the additional requirements for on-prem deployment specific to the airgapped mode?", "reference_output": null}, {"id": "c8c0a65e-7374-4abe-9d68-458a7a0d48c0", "input": "What artifacts do I need to enable explainability for my model? ", "reference_output": null}, {"id": "15379cb5-bba6-43d1-8b2f-80b2a00d0227", "input": "Is KMS required for Arthur's backup and restore capability?", "reference_output": null}, {"id": "242d60dd-516d-4724-b515-fc5acd86f83c", "input": "What Bench scorers can I use for evaluating LLMs at writing summaries?", "reference_output": null}, {"id": "bde29bd5-7fc5-4b40-811f-f03f6a8eeaca", "input": "What Bench scorers can I use for evaluating LLMs at answering questions?", "reference_output": null}, {"id": "7c3bdff6-414e-49b6-ac52-ad6a7d168f13", "input": "What Bench scorers can I use for evaluating LLMs at coding?", "reference_output": null}, {"id": "8d479d1b-5ed7-4926-8d58-5282a8248eee", "input": "How do I view my Bench test results?", "reference_output": null}, {"id": "a88c1ebb-490c-4669-91c3-ca56bc83861e", "input": "What is the difference between Bench test suites and test runs?", "reference_output": null}], "created_at": "2024-03-27T11:29:13.481692", "updated_at": "2024-03-27T11:29:13.481692", "description": null, "last_run_time": "2024-03-27T11:35:08.055206", "num_runs": 32, "page": null, "page_size": null, "total_pages": null, "total_count": null}