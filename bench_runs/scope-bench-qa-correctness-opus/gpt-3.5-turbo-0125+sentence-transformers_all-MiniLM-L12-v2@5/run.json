{"id": "ce93c591-bed7-4412-837c-1afb97fb558b", "name": "gpt-3.5-turbo-0125+sentence-transformers_all-MiniLM-L12-v2@5", "test_suite_id": "4a810683-5bd4-44aa-b42a-784620f41c0d", "test_cases": [{"id": "f879070d-a94a-44c2-9f67-ff60b802b749", "output": "Anomaly Detection, Hot Spots, Explainability, and Bias Mitigation are the enrichments available in Arthur.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "6fc74721-9cba-4844-8f15-f4469422d124", "output": "Generative text models like Large Language Models (LLMs) do not allow for traditional model explainability due to their complexity and the nature of their outputs.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "b63703c2-2fad-47af-9aa3-00b595aeff22", "output": "The enrichments available for object detection models are:\n1. Anomaly Detection\n2. Hot Spots\n3. Explainability\n4. Bias Mitigation", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "f680f682-5b0f-4b7a-8e48-bccb6fd7ee51", "output": "Anomaly Detection, Hot Spots, Explainability, Bias Mitigation", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "d9f912c8-a449-4745-beec-26e562416d08", "output": "The two alert levels available in Arthur are daily and weekly.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "a7abaee1-a0e3-4d8c-bf88-83b546521882", "output": "For on-prem deployment in airgapped mode, the additional requirements include:\n1. An existing private container registry\n2. Existing private Python registries (PyPI, Anaconda) - only required for the model explanation feature\n3. Access to container images and deployment manifest files from specific public registries\n4. Ensure that your private container and Python registries are accessible\n5. Make sure your firewall configurations allow necessary egress and ingress for the platform\n\nFor more detailed information, refer to the \"On-Prem Deployment Requirements\" document.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "e64b4d2b-3e58-4e39-9b23-a639f42f4cd2", "output": "To enable explainability for your model in Arthur, you will need to provide access to your model's predict function. This can be done by creating a model schema that outlines the relationship between your dataset and the model, including information such as model inputs, outputs, data columns, and data access details. Additionally, you will need to provide the necessary artifacts for installing the Arthur platform, which are available on a customer-specific password-protected portal.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "b1c20735-345d-4998-9198-1b64b34239e8", "output": "Yes, KMS is recommended for encrypting data at rest when using Arthur's backup and restore capability.", "score": -1.0, "input": null, "reference_output": null, "score_result": {"score": -1.0, "category": {"name": "invalid", "description": "grader returned an invalid response"}}}, {"id": "64c42b24-cb61-4870-9dfe-679466bf1344", "output": "You can use the \"ExactMatch\" scorer from Bench to evaluate LLMs at writing summaries. This scorer allows you to compare candidate outputs with reference outputs and can be configured to ignore capitalization differences.", "score": 0.0, "input": null, "reference_output": null, "score_result": {"score": 0.0, "category": {"name": "incorrect", "description": "model output is incorrect given the context"}}}, {"id": "22cd57d3-a9a9-4c66-bc14-2e82b0c50449", "output": "You can use the ExactMatch scorer for evaluating LLMs at answering questions.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "ffdb3450-ebb2-49bc-ab2c-c367cc89c4a0", "output": "You can use the custom scorer feature in Bench to evaluate LLM performance. One example is the TrigramRepetition scorer, which evaluates responses based on repeated trigrams. You can define custom scorers like TrigramRepetition to suit your specific evaluation needs.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "a72ef6a5-a67c-47c9-8c66-eb4482504f53", "output": "To view your Bench test results, you can run the Bench UI locally by using the following command: `bench`. This will launch the local UI where you can explore and analyze your test results.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}, {"id": "0af305b2-29b4-476f-a3af-84ee88452b96", "output": "Test Suites store input & reference output data with a scorer, while Test Runs evaluate candidate outputs against the Test Suite's criteria and assign scores to each test case.", "score": 1.0, "input": null, "reference_output": null, "score_result": {"score": 1.0, "category": {"name": "correct", "description": "model output is correct given the context"}}}], "updated_at": "2024-03-27T11:41:58.294703", "created_at": "2024-03-27T11:41:58.294703", "page": null, "page_size": null, "total_pages": null, "total_count": null}