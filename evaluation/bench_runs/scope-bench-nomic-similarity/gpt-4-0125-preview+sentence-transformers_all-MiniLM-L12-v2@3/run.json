{"id": "0d002bb2-3099-436c-9d2a-916c6af39d0c", "name": "gpt-4-0125-preview+sentence-transformers_all-MiniLM-L12-v2@3", "test_suite_id": "1c594684-5fd1-4bba-b209-d6c321bc01ac", "test_cases": [{"id": "6631fb8f-c16e-4b51-9bdb-e46dc35dbe1f", "output": "The enrichments available in Arthur are Anomaly Detection, Bias Mitigation, and Explainability.", "score": 0.9585186839103699, "input": null, "reference_output": null, "score_result": {"score": 0.9585186839103699, "category": null}}, {"id": "12245a16-8cc3-4cad-a0df-8d65b2ccdbb4", "output": "The document does not provide information on model types that do not allow explainability.", "score": 0.8206563591957092, "input": null, "reference_output": null, "score_result": {"score": 0.8206563591957092, "category": null}}, {"id": "907e435b-f3d1-4201-bdf3-a514a8975b2d", "output": "The document does not list specific enrichments available for object detection models.", "score": 0.8090596199035645, "input": null, "reference_output": null, "score_result": {"score": 0.8090596199035645, "category": null}}, {"id": "22d619b4-c43b-4d17-9dd5-1c3d9e81b44a", "output": "The available enrichments for tabular binary classification models are Anomaly Detection, Hot Spots, Explainability, and Bias Mitigation.", "score": 0.7985771894454956, "input": null, "reference_output": null, "score_result": {"score": 0.7985771894454956, "category": null}}, {"id": "c30d8faf-8e01-4e50-b93c-e633c9da7fd1", "output": "The provided context does not contain information about restoring deleted Arthur models.", "score": 0.8137456178665161, "input": null, "reference_output": null, "score_result": {"score": 0.8137456178665161, "category": null}}, {"id": "e9bc0fdf-b920-48eb-bce7-9d10b050a664", "output": "The document does not mention specific alert levels available in Arthur.", "score": 0.8566769957542419, "input": null, "reference_output": null, "score_result": {"score": 0.8566769957542419, "category": null}}, {"id": "4040ca43-f1db-4111-9df4-124ef94eea08", "output": "For an airgap Kubernetes cluster (K8s) installation, the additional requirements include having all the required files downloaded and available locally, as the installation can proceed without Internet access.", "score": 0.6986086368560791, "input": null, "reference_output": null, "score_result": {"score": 0.6986086368560791, "category": null}}, {"id": "498e6ba4-c53d-405d-88bd-88b27aa1106f", "output": "To enable explainability, you will need to provide access to your model's `predict` function.", "score": 0.788661003112793, "input": null, "reference_output": null, "score_result": {"score": 0.788661003112793, "category": null}}, {"id": "3c216b5e-f6ea-41c6-933a-a20d4bf59e08", "output": "No, KMS is not mentioned as a requirement for Arthur's backup and restore capability in the provided context.", "score": 0.763473629951477, "input": null, "reference_output": null, "score_result": {"score": 0.763473629951477, "category": null}}, {"id": "9e8c3e89-6a0c-4ae3-85d6-7a141c9bdcfe", "output": "The document does not mention any specific Bench scorers for evaluating LLMs at writing summaries.", "score": 0.8304141163825989, "input": null, "reference_output": null, "score_result": {"score": 0.8304141163825989, "category": null}}, {"id": "1925c2f0-86e8-4e5c-8c5c-572775db7beb", "output": "The document does not specify the names or types of Bench scorers available for evaluating LLMs at answering questions.", "score": 0.7855546474456787, "input": null, "reference_output": null, "score_result": {"score": 0.7855546474456787, "category": null}}, {"id": "93e6a397-63d3-4678-bb58-42e192ed38c5", "output": "The document does not specify which Bench scorers can be used for evaluating LLMs at coding.", "score": 0.7636771202087402, "input": null, "reference_output": null, "score_result": {"score": 0.7636771202087402, "category": null}}, {"id": "67293353-3c84-4967-810d-ee179a1ae002", "output": "To view your Bench test results locally, set the `BENCH_FILE_DIR` environment variable to point to the location of your new test runs and run `bench` from the command line. This will launch a local UI where you can view your test results.", "score": 0.9473550915718079, "input": null, "reference_output": null, "score_result": {"score": 0.9473550915718079, "category": null}}, {"id": "bb8aa841-074e-4b8f-aa62-ea33d91280bd", "output": "Test suites are created to define the data and evaluation metrics for testing, while test runs execute these test suites against specific model outputs to assess performance.", "score": 0.8459720611572266, "input": null, "reference_output": null, "score_result": {"score": 0.8459720611572266, "category": null}}], "updated_at": "2024-03-26T16:07:26.879785", "created_at": "2024-03-26T16:07:26.879785", "page": null, "page_size": null, "total_pages": null, "total_count": null}