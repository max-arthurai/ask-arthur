{"id": "6b58589e-e698-4b1a-97f1-ffa3aef36167", "name": "gpt-4-0125-preview+nomic-ai_nomic-embed-text-v1.5@7", "test_suite_id": "4feac22d-31c1-42a0-b252-1adca2000ebf", "test_cases": [{"id": "dfdd97cc-9df7-4d98-a306-0f48214d7d27", "output": "The enrichments available in Arthur are Anomaly Detection, Bias Mitigation, and Explainability.", "score": 0.5425406098365784, "input": null, "reference_output": null, "score_result": {"score": 0.5425406098365784, "category": null}}, {"id": "51d72f8a-c329-469e-a00d-7ab12ec66087", "output": "The document does not provide information on model types that do not allow explainability.", "score": 0.6466416716575623, "input": null, "reference_output": null, "score_result": {"score": 0.6466416716575623, "category": null}}, {"id": "5aba4ddc-2962-412b-9dd0-3f14954786a2", "output": "The available enrichments for object detection models are Anomaly Detection, Bias Mitigation, and Explainability.", "score": 0.6603832840919495, "input": null, "reference_output": null, "score_result": {"score": 0.6603832840919495, "category": null}}, {"id": "c5142157-54c1-4f56-a2e5-21202a2e20fb", "output": "The available enrichments for tabular binary classification models are Anomaly Detection, Hot Spots, Explainability, and Bias Mitigation.", "score": 0.5702216029167175, "input": null, "reference_output": null, "score_result": {"score": 0.5702216029167175, "category": null}}, {"id": "7fa1360f-9632-44d7-8868-6d5b45d1f1d1", "output": "The provided context does not contain information about restoring deleted Arthur models.", "score": 0.47069570422172546, "input": null, "reference_output": null, "score_result": {"score": 0.47069570422172546, "category": null}}, {"id": "a3688edd-c062-4d5d-8542-c526075e8785", "output": "The document does not mention specific alert levels available in Arthur.", "score": 0.5984597206115723, "input": null, "reference_output": null, "score_result": {"score": 0.5984597206115723, "category": null}}, {"id": "0c2c9c1a-7769-4c81-b695-7388ddcbbf4e", "output": "For an airgap Kubernetes cluster install, the additional requirements include downloading all necessary files and artifacts beforehand since there will be no internet access, and ensuring the Kubernetes cluster has connectivity to a private container and PyPI/Conda registry for optimal platform utilization.", "score": 0.510113537311554, "input": null, "reference_output": null, "score_result": {"score": 0.510113537311554, "category": null}}, {"id": "c265c857-9311-49d2-9b89-24603aaab946", "output": "To enable explainability, you need to provide access to your model's `predict` function.", "score": 0.4802130162715912, "input": null, "reference_output": null, "score_result": {"score": 0.4802130162715912, "category": null}}, {"id": "9d51a3ac-a7cb-4b13-92f6-a137c59d409a", "output": "No, KMS is not mentioned as a requirement for Arthur's backup and restore capability in the provided context.", "score": 0.5428208112716675, "input": null, "reference_output": null, "score_result": {"score": 0.5428208112716675, "category": null}}, {"id": "b32f4653-bad2-4180-8afc-b04bc0b53323", "output": "The document does not mention any specific Bench scorers for evaluating LLMs at writing summaries.", "score": 0.46995997428894043, "input": null, "reference_output": null, "score_result": {"score": 0.46995997428894043, "category": null}}, {"id": "5e742e10-1dcd-43b0-9d5a-b0227a8bfc3d", "output": "The document does not specify the names or types of Bench scorers available for evaluating LLMs at answering questions.", "score": 0.39804768562316895, "input": null, "reference_output": null, "score_result": {"score": 0.39804768562316895, "category": null}}, {"id": "0ba7dcb4-e439-418f-b09d-24a120339ddc", "output": "The document does not specify which Bench scorers can be used for evaluating LLMs at coding.", "score": 0.48652198910713196, "input": null, "reference_output": null, "score_result": {"score": 0.48652198910713196, "category": null}}, {"id": "05adad2b-eecc-422e-8877-1868229f1565", "output": "To view your Bench test results locally, set the `BENCH_FILE_DIR` environment variable to point to the location of your new test runs and run `bench` from the command line.", "score": 0.720098614692688, "input": null, "reference_output": null, "score_result": {"score": 0.720098614692688, "category": null}}, {"id": "e0af19dd-7279-4fbe-8a91-e87d36c31a69", "output": "A Bench test suite is created to define the data and evaluation criteria for testing, while a test run is the execution of a test suite against a set of candidate outputs to evaluate performance.", "score": 0.6241124272346497, "input": null, "reference_output": null, "score_result": {"score": 0.6241124272346497, "category": null}}], "updated_at": "2024-03-26T15:31:46.054843", "created_at": "2024-03-26T15:31:46.054843", "page": null, "page_size": null, "total_pages": null, "total_count": null}