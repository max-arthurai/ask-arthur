{"id": "8129b1a1-92a1-4df8-856d-2db869cfbc1e", "name": "gpt-4-0125-preview+sentence-transformers_all-MiniLM-L12-v2@5", "test_suite_id": "4feac22d-31c1-42a0-b252-1adca2000ebf", "test_cases": [{"id": "dfdd97cc-9df7-4d98-a306-0f48214d7d27", "output": "The enrichments available in Arthur are Anomaly Detection, Bias Mitigation, and Explainability.", "score": 0.5425406098365784, "input": null, "reference_output": null, "score_result": {"score": 0.5425406098365784, "category": null}}, {"id": "51d72f8a-c329-469e-a00d-7ab12ec66087", "output": "The document does not provide information on model types that do not allow explainability.", "score": 0.6466416716575623, "input": null, "reference_output": null, "score_result": {"score": 0.6466416716575623, "category": null}}, {"id": "5aba4ddc-2962-412b-9dd0-3f14954786a2", "output": "The document does not specify the enrichments available for object detection models.", "score": 0.5988750457763672, "input": null, "reference_output": null, "score_result": {"score": 0.5988750457763672, "category": null}}, {"id": "c5142157-54c1-4f56-a2e5-21202a2e20fb", "output": "The available enrichments for tabular binary classification models are Anomaly Detection, Hot Spots, Explainability, and Bias Mitigation.", "score": 0.5702216029167175, "input": null, "reference_output": null, "score_result": {"score": 0.5702216029167175, "category": null}}, {"id": "7fa1360f-9632-44d7-8868-6d5b45d1f1d1", "output": "The provided document does not contain information regarding the restoration of deleted Arthur models.", "score": 0.47458773851394653, "input": null, "reference_output": null, "score_result": {"score": 0.47458773851394653, "category": null}}, {"id": "a3688edd-c062-4d5d-8542-c526075e8785", "output": "The document does not provide information on specific alert levels available in Arthur.", "score": 0.5787457823753357, "input": null, "reference_output": null, "score_result": {"score": 0.5787457823753357, "category": null}}, {"id": "0c2c9c1a-7769-4c81-b695-7388ddcbbf4e", "output": "For airgapped mode, all required files must be downloaded and available locally, and the Kubernetes cluster does not need Internet access once these files are obtained.", "score": 0.4396551549434662, "input": null, "reference_output": null, "score_result": {"score": 0.4396551549434662, "category": null}}, {"id": "c265c857-9311-49d2-9b89-24603aaab946", "output": "To enable explainability, you need to provide access to your model's `predict` function.", "score": 0.4802130162715912, "input": null, "reference_output": null, "score_result": {"score": 0.4802130162715912, "category": null}}, {"id": "9d51a3ac-a7cb-4b13-92f6-a137c59d409a", "output": "No, KMS is not mentioned as a requirement for Arthur's backup and restore capability in the provided context.", "score": 0.5428208112716675, "input": null, "reference_output": null, "score_result": {"score": 0.5428208112716675, "category": null}}, {"id": "b32f4653-bad2-4180-8afc-b04bc0b53323", "output": "The document does not mention any specific Bench scorers for evaluating LLMs at writing summaries.", "score": 0.46995997428894043, "input": null, "reference_output": null, "score_result": {"score": 0.46995997428894043, "category": null}}, {"id": "5e742e10-1dcd-43b0-9d5a-b0227a8bfc3d", "output": "The document does not specify the names of Bench scorers for evaluating LLMs at answering questions.", "score": 0.4082629382610321, "input": null, "reference_output": null, "score_result": {"score": 0.4082629382610321, "category": null}}, {"id": "0ba7dcb4-e439-418f-b09d-24a120339ddc", "output": "The document does not specify which Bench scorers can be used for evaluating LLMs at coding.", "score": 0.48652198910713196, "input": null, "reference_output": null, "score_result": {"score": 0.48652198910713196, "category": null}}, {"id": "05adad2b-eecc-422e-8877-1868229f1565", "output": "To view your Bench test results locally, set the `BENCH_FILE_DIR` environment variable to point to the location of your new test runs and run `bench` from the command line.", "score": 0.720098614692688, "input": null, "reference_output": null, "score_result": {"score": 0.720098614692688, "category": null}}, {"id": "e0af19dd-7279-4fbe-8a91-e87d36c31a69", "output": "Test suites are created to define the data and evaluation criteria for testing, while test runs execute these test suites against specific model outputs to assess performance.", "score": 0.5930477380752563, "input": null, "reference_output": null, "score_result": {"score": 0.5930477380752563, "category": null}}], "updated_at": "2024-03-26T15:31:43.072799", "created_at": "2024-03-26T15:31:43.072799", "page": null, "page_size": null, "total_pages": null, "total_count": null}